---
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999, digits = 3)
```

## Introduçao

Esse repositório contém códigos do desafio Zindi Africa. Aqui, é descrito todo o processo para chegar no resultado final. Os códigos completos do estudo estão no arquivo `CaseAnaliseDados.R`. Os dados, obtidos de https://zindi.africa/competitions/financial-inclusion-in-africa/data estão na pasta `data`.

O objetivo é fazer um modelo que identifique quais pessoas possuem conta no banco, correspondente a variável `bank_account`.

O desafio foi feito na linguagem `R` e as etapas do processo são:

- Análise exploratória dos dados
- Balanceamento de variáveis
- Modelagem
- Resultados

## Importações

Os pacotes `data.table` e `tidyverse` (que inclui `dplyr`, `tidyr` e outros) serão utilizados para as operações de *data wrangling*. Para as visualizações, utilizarei o `ggplot2` (incluído no `tidyverse`) e `magick`; enquanto que os pacotes `caret`, `pROC` e `xgboost` serão utilizados na parte de *machine learning*.

Os dados originais estão divididos entre treino e teste, sendo que o teste não contém a variável resposta. 

## Análise Exploratória dos Dados

```{r echo=FALSE, warning=F, message=F}
library(data.table)
library(tidyverse)
library(magick)
library(caret)
library(pROC)
library(xgboost)

ag_colors <- c('#3e6dbe', '#78ca35', '#253165')

vars <- fread('data/VariableDefinitions.csv', header = T, encoding = 'UTF-8')
train <- fread('data/Train_v2.csv')
test <- fread('data/Test_v2.csv')
```


``` {r}

names(train)

```


```{r, echo=FALSE}

logo <- image_read("https://logospng.org/download/agibank/logo-agibank-icon-2048.png")

perc_bank <- train[, .(n = .N), bank_account][, perc := round(n / sum(n), 2)][]

p1 <- ggplot(perc_bank, aes(x = bank_account, y = n, fill = bank_account)) +
  geom_col(position = "dodge") +
  geom_text(
    aes(x = bank_account, y = n, label = paste0(perc * 100, '%')),
    position = position_dodge(width = 1),
    vjust = -0.5, size = 4
  ) + 
  scale_fill_manual(values = ag_colors) + 
  labs(title = 'DESBALANÇO ENTRE AS VARIÁVEIS RESPOSTA',
       subtitle = 'CONTAGEM POR CATEGORIA',
       fill = 'CONTA NO BANCO') +
  theme_minimal() +
  theme(axis.title = element_blank())

p1
grid::grid.raster(logo, x = .98, y = 0.015, just = c('right', 'bottom'), width = unit(.3, 'inches'))

```

Há um desbalanço na variável resposta. Isso deve ser levado em consideração na hora de treinar o modelo, pois datasets desbalanceados podem influenciar no resultado do modelo.


```{r, echo=FALSE}

perc_country <- train[, .(n = .N), by = .(country, bank_account)][, perc := round( n / sum(n), 2), country][]

p2 <- ggplot(perc_country, aes(x = country, 
                               y =  n,
                               fill = bank_account)) +
  geom_col(position = "dodge") +
  geom_text(
    aes(x = country, y = n, label = paste0(perc *100, '%')),
    position = position_dodge(width = 1),
    vjust = -0.5, size = 4
  ) + 
  scale_fill_manual(values = ag_colors) + 
  labs(title = 'Contagem de pessoas que possuem conta no banco por País',
       fill = 'Conta no banco') +
  theme_minimal() +
  theme(axis.title = element_blank(), 
        plot.title = element_text(size = 16))

p2
grid::grid.raster(logo, x = .98, y = 0.015, just = c('right', 'bottom'), width = unit(.3, 'inches'))


```

Os países apresentam taxas diferentes de pessoas com contas bancárias. 

## Modelagem

O primeiro passo a ser feito é rodar um modelo de *machine learning* e vermos os resultados iniciais obtidos, para então tomarmos a decisão de que caminho seguir. Como não temos a variável resposta no dataset de teste, iremos criar um dataset de validação a partir do dataset de treino, que ficará de fora do treinamento do nosso modelo, para que possamos avaliar como ele está performando.

O pacote `caret` tem uma função que facilita o processo de dividir o dataset de maneira distribuida como o dataset original. 75% do dataset original permaneceu no dataset de treino, e 25% ficou separado no de validação.

``` {r eval = F}

trainIndex <- createDataPartition(train$bank_account, p = .75, 
                                  list = FALSE, times = 1)

validation <- train[-trainIndex]
train <- train[trainIndex]

```


Para treinar nosso primeiro modelo, utilizaremos a metodologia *Random Forest*, modelo não-paramétrico que se adapta bem a diversos tipos de dataset. Ele utiliza apenas um hiperparâmetro, o `mtry`. Uma regra de bolso é utilizar a raiz quadrada do número de variáveis do dataset para o `mtry`. Também utilizaremos o método de *Cross Validation*.

``` {r eval = F}

trcontrol = trainControl( method = "cv",
                          number = 5,  
                          allowParallel = TRUE,
                          verboseIter = TRUE )

mtry <- sqrt(ncol(train[, -'bank_account', with=F]))
tunegrid <- expand.grid(.mtry=mtry)

rf_model <- train(x = train[, -'bank_account', with=F], 
                  y = y_train,
                  trControl = trcontrol,
                  tuneGrid = tunegrid,
                  method = "rf")

```
